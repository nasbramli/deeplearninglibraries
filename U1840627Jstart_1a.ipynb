{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Use [markdown](https://www.markdownguide.org/basic-syntax/) to label each (sub)question neatly.\n",
        "\n",
        "This notebook serves as your report. All your answers should be presented within it.\n",
        "\n",
        "You can submit multiple notebooks (e.g. 1 notebook per part / question).\n",
        "\n",
        "Before submission, remember to tidy up the notebook and retain only relevant parts."
      ],
      "metadata": {
        "id": "6svEX4UE2txX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnbEEvqnYwh6",
        "outputId": "91e5c051-24bc-45db-92bb-2a9ae2e8cf1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_path='/content/drive/MyDrive/full.csv'"
      ],
      "metadata": {
        "id": "jkWisO6vY_-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import IPython.display as ipd\n",
        "\n",
        "from scipy.io import wavfile as wav\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
        "\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau,EarlyStopping,ModelCheckpoint,LearningRateScheduler\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.utils import np_utils\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, callbacks, optimizers"
      ],
      "metadata": {
        "id": "vr3BLitFduby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YM8unKH7nSIM"
      },
      "source": [
        "SEED = 42\n",
        "\n",
        "import os\n",
        "os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
        "\n",
        "import random\n",
        "random.seed(SEED)\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(SEED)\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(SEED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmTBl3xoqA9g"
      },
      "source": [
        "# Read Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "An4b9d12p8u2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "e16a1492-1a89-40d3-d9df-9a153adb08c3"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/full.csv')\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          filename       tempo  total_beats  average_beats  \\\n",
              "0  app_3001_4001_phnd_neg_0000.wav  184.570312          623      69.222222   \n",
              "1  app_3001_4001_phnd_neg_0001.wav  151.999081          521      74.428571   \n",
              "2  app_3001_4001_phnd_neg_0002.wav  112.347147         1614     146.727273   \n",
              "3  app_3001_4001_phnd_neg_0003.wav  107.666016         2060     158.461538   \n",
              "4  app_3001_4001_phnd_neg_0004.wav   75.999540           66      33.000000   \n",
              "\n",
              "   chroma_stft_mean  chroma_stft_var  chroma_cq_mean  chroma_cq_var  \\\n",
              "0          0.515281         0.093347        0.443441       0.082742   \n",
              "1          0.487201         0.094461        0.542182       0.073359   \n",
              "2          0.444244         0.099268        0.442014       0.083224   \n",
              "3          0.454156         0.100834        0.424370       0.084435   \n",
              "4          0.478780         0.100000        0.414859       0.089313   \n",
              "\n",
              "   chroma_cens_mean  chroma_cens_var  ...  mfcc15_mean  mfcc15_var  \\\n",
              "0          0.249143         0.021261  ...   -10.669799   63.340282   \n",
              "1          0.274423         0.008025  ...    -5.666375   90.256195   \n",
              "2          0.264430         0.013410  ...    -5.502390   73.079750   \n",
              "3          0.257672         0.016938  ...    -8.812989   93.791893   \n",
              "4          0.252143         0.019757  ...    -6.584204   64.973305   \n",
              "\n",
              "   mfcc16_mean  mfcc16_var  mfcc17_mean  mfcc17_var  mfcc18_mean  mfcc18_var  \\\n",
              "0     1.811605   58.117188    -3.286546   54.268448    -2.719069   59.548176   \n",
              "1     1.573594  105.070496    -0.742024   82.417496    -1.961745  119.312355   \n",
              "2     0.202623   72.040550    -4.021009   73.844353    -5.916223  103.834824   \n",
              "3    -0.429413   60.002579    -4.013513   82.544540    -5.858006   84.402092   \n",
              "4     0.744403   68.908516    -6.354805   66.414391    -6.555534   47.852840   \n",
              "\n",
              "   mfcc19_mean  mfcc19_var  \n",
              "0    -4.559987   70.774803  \n",
              "1     1.513660  101.014572  \n",
              "2    -2.939086  113.598824  \n",
              "3     0.686969   90.126389  \n",
              "4    -4.809713   73.033966  \n",
              "\n",
              "[5 rows x 78 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9a964160-2e63-48d3-80a3-3592ef7eccdf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>tempo</th>\n",
              "      <th>total_beats</th>\n",
              "      <th>average_beats</th>\n",
              "      <th>chroma_stft_mean</th>\n",
              "      <th>chroma_stft_var</th>\n",
              "      <th>chroma_cq_mean</th>\n",
              "      <th>chroma_cq_var</th>\n",
              "      <th>chroma_cens_mean</th>\n",
              "      <th>chroma_cens_var</th>\n",
              "      <th>...</th>\n",
              "      <th>mfcc15_mean</th>\n",
              "      <th>mfcc15_var</th>\n",
              "      <th>mfcc16_mean</th>\n",
              "      <th>mfcc16_var</th>\n",
              "      <th>mfcc17_mean</th>\n",
              "      <th>mfcc17_var</th>\n",
              "      <th>mfcc18_mean</th>\n",
              "      <th>mfcc18_var</th>\n",
              "      <th>mfcc19_mean</th>\n",
              "      <th>mfcc19_var</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>app_3001_4001_phnd_neg_0000.wav</td>\n",
              "      <td>184.570312</td>\n",
              "      <td>623</td>\n",
              "      <td>69.222222</td>\n",
              "      <td>0.515281</td>\n",
              "      <td>0.093347</td>\n",
              "      <td>0.443441</td>\n",
              "      <td>0.082742</td>\n",
              "      <td>0.249143</td>\n",
              "      <td>0.021261</td>\n",
              "      <td>...</td>\n",
              "      <td>-10.669799</td>\n",
              "      <td>63.340282</td>\n",
              "      <td>1.811605</td>\n",
              "      <td>58.117188</td>\n",
              "      <td>-3.286546</td>\n",
              "      <td>54.268448</td>\n",
              "      <td>-2.719069</td>\n",
              "      <td>59.548176</td>\n",
              "      <td>-4.559987</td>\n",
              "      <td>70.774803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>app_3001_4001_phnd_neg_0001.wav</td>\n",
              "      <td>151.999081</td>\n",
              "      <td>521</td>\n",
              "      <td>74.428571</td>\n",
              "      <td>0.487201</td>\n",
              "      <td>0.094461</td>\n",
              "      <td>0.542182</td>\n",
              "      <td>0.073359</td>\n",
              "      <td>0.274423</td>\n",
              "      <td>0.008025</td>\n",
              "      <td>...</td>\n",
              "      <td>-5.666375</td>\n",
              "      <td>90.256195</td>\n",
              "      <td>1.573594</td>\n",
              "      <td>105.070496</td>\n",
              "      <td>-0.742024</td>\n",
              "      <td>82.417496</td>\n",
              "      <td>-1.961745</td>\n",
              "      <td>119.312355</td>\n",
              "      <td>1.513660</td>\n",
              "      <td>101.014572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>app_3001_4001_phnd_neg_0002.wav</td>\n",
              "      <td>112.347147</td>\n",
              "      <td>1614</td>\n",
              "      <td>146.727273</td>\n",
              "      <td>0.444244</td>\n",
              "      <td>0.099268</td>\n",
              "      <td>0.442014</td>\n",
              "      <td>0.083224</td>\n",
              "      <td>0.264430</td>\n",
              "      <td>0.013410</td>\n",
              "      <td>...</td>\n",
              "      <td>-5.502390</td>\n",
              "      <td>73.079750</td>\n",
              "      <td>0.202623</td>\n",
              "      <td>72.040550</td>\n",
              "      <td>-4.021009</td>\n",
              "      <td>73.844353</td>\n",
              "      <td>-5.916223</td>\n",
              "      <td>103.834824</td>\n",
              "      <td>-2.939086</td>\n",
              "      <td>113.598824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>app_3001_4001_phnd_neg_0003.wav</td>\n",
              "      <td>107.666016</td>\n",
              "      <td>2060</td>\n",
              "      <td>158.461538</td>\n",
              "      <td>0.454156</td>\n",
              "      <td>0.100834</td>\n",
              "      <td>0.424370</td>\n",
              "      <td>0.084435</td>\n",
              "      <td>0.257672</td>\n",
              "      <td>0.016938</td>\n",
              "      <td>...</td>\n",
              "      <td>-8.812989</td>\n",
              "      <td>93.791893</td>\n",
              "      <td>-0.429413</td>\n",
              "      <td>60.002579</td>\n",
              "      <td>-4.013513</td>\n",
              "      <td>82.544540</td>\n",
              "      <td>-5.858006</td>\n",
              "      <td>84.402092</td>\n",
              "      <td>0.686969</td>\n",
              "      <td>90.126389</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>app_3001_4001_phnd_neg_0004.wav</td>\n",
              "      <td>75.999540</td>\n",
              "      <td>66</td>\n",
              "      <td>33.000000</td>\n",
              "      <td>0.478780</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.414859</td>\n",
              "      <td>0.089313</td>\n",
              "      <td>0.252143</td>\n",
              "      <td>0.019757</td>\n",
              "      <td>...</td>\n",
              "      <td>-6.584204</td>\n",
              "      <td>64.973305</td>\n",
              "      <td>0.744403</td>\n",
              "      <td>68.908516</td>\n",
              "      <td>-6.354805</td>\n",
              "      <td>66.414391</td>\n",
              "      <td>-6.555534</td>\n",
              "      <td>47.852840</td>\n",
              "      <td>-4.809713</td>\n",
              "      <td>73.033966</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 78 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9a964160-2e63-48d3-80a3-3592ef7eccdf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9a964160-2e63-48d3-80a3-3592ef7eccdf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9a964160-2e63-48d3-80a3-3592ef7eccdf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'] = df['filename'].str.split('_').str[-2]"
      ],
      "metadata": {
        "id": "6AI_2ZahhQtk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHZQbQVzqGIA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f16ac0e-5825-4675-b6ae-3f8ade6a5c05"
      },
      "source": [
        "df['label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pos    92826\n",
              "neg    89428\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zp_RDMgqL9Z"
      },
      "source": [
        "Split and scale dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fNTd9t7qHCI"
      },
      "source": [
        "columns_to_drop = ['label','filename']\n",
        "\n",
        "def split_dataset(df, columns_to_drop, test_size, random_state):\n",
        "  label_encoder = preprocessing.LabelEncoder()\n",
        "\n",
        "  df['label'] = label_encoder.fit_transform(df['label'])\n",
        "\n",
        "  df_train, df_test = train_test_split(df, test_size=test_size, random_state=random_state)\n",
        "\n",
        "  df_train2 = df_train.drop(columns_to_drop,axis=1)\n",
        "  y_train2 = df_train['label'].to_numpy()\n",
        "\n",
        "  df_test2 = df_test.drop(columns_to_drop,axis=1)\n",
        "  y_test2 = df_test['label'].to_numpy()\n",
        "\n",
        "  return df_train2, y_train2, df_test2, y_test2\n",
        "\n",
        "def preprocess_dataset(df_train, df_test):\n",
        "\n",
        "  standard_scaler = preprocessing.StandardScaler()\n",
        "  df_train_scaled = standard_scaler.fit_transform(df_train)\n",
        "\n",
        "  df_test_scaled = standard_scaler.transform(df_test)\n",
        "\n",
        "  return df_train_scaled, df_test_scaled\n",
        "\n",
        "X_train, y_train, X_test, y_test = split_dataset(df, columns_to_drop, test_size=0.3, random_state=0) # positive labels being encoded as 1\n",
        "\n",
        "X_train_scaled, X_test_scaled = preprocess_dataset(X_train, X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaled.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhKHaQnwdke_",
        "outputId": "a61fe06c-e07c-4c92-b533-864af469d18f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(127577, 77)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(batch_size):\n",
        "  ffn = models.Sequential()\n",
        "  ffn.add(layers.Dense(units=128, activation='relu', input_shape=(77,)))\n",
        "  ffn.add(layers.Dense(units=128, activation='relu'))\n",
        "  ffn.add(layers.Dense(units=128, activation='relu'))\n",
        "  ffn.add(layers.Dense(units=1, activation='sigmoid'))\n",
        "  opt=optimizers.Adam()\n",
        "  ffn.compile(\n",
        "      optimizer=opt,\n",
        "      loss='BinaryCrossentropy',\n",
        "      metrics=['accuracy']\n",
        "  )\n",
        "\n",
        "  return ffn"
      ],
      "metadata": {
        "id": "jR_DRtaSalAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ffn=build_model(3)\n",
        "ffn.build()\n",
        "ffn.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dz1jCOlqf7a9",
        "outputId": "0624f092-c405-47ae-bd83-2a954b140af8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 128)               9984      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 43,137\n",
            "Trainable params: 43,137\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from keras.callbacks import Callback\n",
        "from timeit import default_timer as timer"
      ],
      "metadata": {
        "id": "-FwHKxIX1_tZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TimingCallback(Callback):\n",
        "  def __init__(self, logs={}):\n",
        "    self.logs=[]\n",
        "  def on_epoch_begin(self, epoch, logs={}):\n",
        "    self.starttime = timer()\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    self.logs.append(timer()-self.starttime)\n",
        "\n",
        "time = TimingCallback()"
      ],
      "metadata": {
        "id": "RhNofQW33KLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size1b=256\n",
        "accuracy_dict1b={}\n",
        "time_dict1b={}\n",
        "no_epochs=100"
      ],
      "metadata": {
        "id": "wnWVthKg51tE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Qn 1**\n",
        "a. Use the training dataset to train the model for 100 epochs. Implement early stopping with patience 3."
      ],
      "metadata": {
        "id": "TjbRKMU8z0Wk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies1b=[]\n",
        "training_times1b=[]\n",
        "\n",
        "stop_early = callbacks.EarlyStopping(\n",
        "                            monitor='val_loss', patience=3)\n",
        "checkpoint = callbacks.ModelCheckpoint(\n",
        "                        'fnn_model.hdf5',\n",
        "                        verbose=1,\n",
        "                        save_best_only=True,\n",
        "                        monitor='val_loss')\n",
        "X_train, X_test = X_train_scaled, X_train_scaled\n",
        "Y_train, Y_test = y_train, y_train\n",
        "main_model = build_model(batch_size1b)\n",
        "main_model.summary()\n",
        "hist = main_model.fit(x=X_train,\n",
        "                              y=Y_train,\n",
        "                              validation_data=(X_test, Y_test),\n",
        "                              epochs=no_epochs,\n",
        "                              verbose=0,\n",
        "                              callbacks=[stop_early, checkpoint, time])\n",
        "\n",
        "accuracies1b.append(hist.history['accuracy'][-1])\n",
        "training_times1b.append(time.logs[-1])\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "accuracy_dict1b[f'{batch_size1b}'] = accuracies1b\n",
        "time_dict1b[f'{batch_size1b}'] = training_times1b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YF69_NlpNPk",
        "outputId": "8054a324-12ac-4e55-fbad-a3c37ceb78d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 128)               9984      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 43,137\n",
            "Trainable params: 43,137\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.67785, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 2: val_loss improved from 0.67785 to 0.66439, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 3: val_loss improved from 0.66439 to 0.64376, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 4: val_loss improved from 0.64376 to 0.62084, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 5: val_loss improved from 0.62084 to 0.60222, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 6: val_loss improved from 0.60222 to 0.57954, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 7: val_loss improved from 0.57954 to 0.56066, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 8: val_loss improved from 0.56066 to 0.54724, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 9: val_loss improved from 0.54724 to 0.52709, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 10: val_loss improved from 0.52709 to 0.51460, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 11: val_loss improved from 0.51460 to 0.50553, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 12: val_loss improved from 0.50553 to 0.48530, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 13: val_loss improved from 0.48530 to 0.47939, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 14: val_loss improved from 0.47939 to 0.45939, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 15: val_loss improved from 0.45939 to 0.45659, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 16: val_loss improved from 0.45659 to 0.45063, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 17: val_loss improved from 0.45063 to 0.43893, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 18: val_loss improved from 0.43893 to 0.42996, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 19: val_loss improved from 0.42996 to 0.42103, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 20: val_loss improved from 0.42103 to 0.41164, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 21: val_loss improved from 0.41164 to 0.40656, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 22: val_loss improved from 0.40656 to 0.40305, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 23: val_loss improved from 0.40305 to 0.39176, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 24: val_loss improved from 0.39176 to 0.39085, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 25: val_loss improved from 0.39085 to 0.37949, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 26: val_loss improved from 0.37949 to 0.37068, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 27: val_loss improved from 0.37068 to 0.36896, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 28: val_loss did not improve from 0.36896\n",
            "\n",
            "Epoch 29: val_loss improved from 0.36896 to 0.35981, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 30: val_loss did not improve from 0.35981\n",
            "\n",
            "Epoch 31: val_loss improved from 0.35981 to 0.35050, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 32: val_loss improved from 0.35050 to 0.33755, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 33: val_loss did not improve from 0.33755\n",
            "\n",
            "Epoch 34: val_loss improved from 0.33755 to 0.33584, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 35: val_loss improved from 0.33584 to 0.33115, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 36: val_loss improved from 0.33115 to 0.32585, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 37: val_loss improved from 0.32585 to 0.32368, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 38: val_loss did not improve from 0.32368\n",
            "\n",
            "Epoch 39: val_loss improved from 0.32368 to 0.31379, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 40: val_loss improved from 0.31379 to 0.31001, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 41: val_loss did not improve from 0.31001\n",
            "\n",
            "Epoch 42: val_loss improved from 0.31001 to 0.30365, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 43: val_loss improved from 0.30365 to 0.29898, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 44: val_loss improved from 0.29898 to 0.29670, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 45: val_loss improved from 0.29670 to 0.29418, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 46: val_loss improved from 0.29418 to 0.29317, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 47: val_loss improved from 0.29317 to 0.28763, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 48: val_loss did not improve from 0.28763\n",
            "\n",
            "Epoch 49: val_loss did not improve from 0.28763\n",
            "\n",
            "Epoch 50: val_loss improved from 0.28763 to 0.27776, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 51: val_loss improved from 0.27776 to 0.27488, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 52: val_loss improved from 0.27488 to 0.27386, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 53: val_loss did not improve from 0.27386\n",
            "\n",
            "Epoch 54: val_loss improved from 0.27386 to 0.26812, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 55: val_loss did not improve from 0.26812\n",
            "\n",
            "Epoch 56: val_loss improved from 0.26812 to 0.26658, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 57: val_loss improved from 0.26658 to 0.26474, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 58: val_loss improved from 0.26474 to 0.26189, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 59: val_loss did not improve from 0.26189\n",
            "\n",
            "Epoch 60: val_loss improved from 0.26189 to 0.25265, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 61: val_loss did not improve from 0.25265\n",
            "\n",
            "Epoch 62: val_loss did not improve from 0.25265\n",
            "\n",
            "Epoch 63: val_loss improved from 0.25265 to 0.25165, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 64: val_loss improved from 0.25165 to 0.24838, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 65: val_loss improved from 0.24838 to 0.24525, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 66: val_loss improved from 0.24525 to 0.24154, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 67: val_loss did not improve from 0.24154\n",
            "\n",
            "Epoch 68: val_loss did not improve from 0.24154\n",
            "\n",
            "Epoch 69: val_loss improved from 0.24154 to 0.23884, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 70: val_loss improved from 0.23884 to 0.23883, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 71: val_loss did not improve from 0.23883\n",
            "\n",
            "Epoch 72: val_loss improved from 0.23883 to 0.23630, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 73: val_loss improved from 0.23630 to 0.22899, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 74: val_loss did not improve from 0.22899\n",
            "\n",
            "Epoch 75: val_loss did not improve from 0.22899\n",
            "\n",
            "Epoch 76: val_loss did not improve from 0.22899\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_dict1b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O42skHdIups4",
        "outputId": "4bca067d-f3ba-4b88-efbb-00e416dfa3af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'256': [0.8854417204856873]}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "time_dict1b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwgr5-y5uzqf",
        "outputId": "748db617-8f76-4065-8fe5-694187322079"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'256': [11.471040356000003]}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Qn 1**\n",
        "b. Plot train and test accuracies and losses on training and test data against training epochs and comment on the line plots. Explain the use of early stopping in this question."
      ],
      "metadata": {
        "id": "aUU1-JD90IS4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hist.history['accuracy']\n",
        "hist.history['val_accuracy']\n",
        "hist.history['loss']\n",
        "hist.history['val_loss']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tD7196sDxzb3",
        "outputId": "e1cf49e1-2291-46d4-bef2-890bba911394"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6784477829933167,\n",
              " 0.6637735962867737,\n",
              " 0.6427755355834961,\n",
              " 0.6209833025932312,\n",
              " 0.5976155996322632,\n",
              " 0.5758463740348816,\n",
              " 0.5563440918922424,\n",
              " 0.5396587252616882,\n",
              " 0.5191901326179504,\n",
              " 0.501625657081604,\n",
              " 0.4912107288837433,\n",
              " 0.4772253632545471,\n",
              " 0.47107788920402527,\n",
              " 0.45020782947540283,\n",
              " 0.4384983777999878,\n",
              " 0.43398457765579224,\n",
              " 0.42241019010543823,\n",
              " 0.40760236978530884,\n",
              " 0.40255776047706604,\n",
              " 0.39877328276634216,\n",
              " 0.38903942704200745,\n",
              " 0.38291820883750916,\n",
              " 0.37507718801498413,\n",
              " 0.36307764053344727,\n",
              " 0.36687541007995605,\n",
              " 0.35716965794563293,\n",
              " 0.34955132007598877,\n",
              " 0.3447866141796112,\n",
              " 0.342682808637619,\n",
              " 0.33453643321990967,\n",
              " 0.3240881860256195,\n",
              " 0.32296890020370483,\n",
              " 0.32148051261901855,\n",
              " 0.30788061022758484,\n",
              " 0.31364163756370544,\n",
              " 0.305912047624588,\n",
              " 0.3030003011226654,\n",
              " 0.3027222156524658,\n",
              " 0.29350149631500244,\n",
              " 0.29099124670028687,\n",
              " 0.2848329246044159,\n",
              " 0.28033703565597534,\n",
              " 0.2831023037433624,\n",
              " 0.2718101143836975,\n",
              " 0.2767130434513092,\n",
              " 0.2677062451839447,\n",
              " 0.26357418298721313,\n",
              " 0.2612020671367645,\n",
              " 0.25970011949539185,\n",
              " 0.25402021408081055,\n",
              " 0.25536641478538513,\n",
              " 0.2528139650821686,\n",
              " 0.25876492261886597,\n",
              " 0.2564018964767456,\n",
              " 0.25231605768203735,\n",
              " 0.2521544098854065,\n",
              " 0.24541974067687988,\n",
              " 0.23315609991550446,\n",
              " 0.23994377255439758,\n",
              " 0.23241111636161804,\n",
              " 0.2388489991426468,\n",
              " 0.22441783547401428,\n",
              " 0.22161763906478882,\n",
              " 0.22481265664100647,\n",
              " 0.22796368598937988,\n",
              " 0.23078040778636932]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(hist.history['accuracy'])\n",
        "plt.plot(hist.history['val_accuracy'])\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('Q1bgraph')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "wCAe5feUxa3X",
        "outputId": "1fb044a8-cc92-43ca-9db1-2886320440f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Early stopping is generally used to avoid over-fitting when the training model with iterative model is used, such as the adam optimiser for this method, and it would cause the model to have poor perfromance on the test set."
      ],
      "metadata": {
        "id": "IE8RrxX8Vrhi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Qn 2**\n",
        "a. Plot mean cross-validation accuracies on the final epoch for different batch sizes as a scatter plot. Limit search space to batch size [128, 256, 512, 1024].\n"
      ],
      "metadata": {
        "id": "3rdyeI71vsfO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size_list2a=[128,256, 512,1024]\n",
        "accuracy_dict2a={}\n",
        "time_dict2a={}\n",
        "\n",
        "for batch_size in batch_size_list2a:\n",
        "    kfold = KFold(n_splits=5)\n",
        "    accuracies2a = []\n",
        "    training_times2a = []\n",
        "    for train_index, test_index in kfold.split(X_train_scaled):\n",
        "        stop_early = callbacks.EarlyStopping(\n",
        "                            monitor='val_loss', patience=3)\n",
        "        checkpoint = callbacks.ModelCheckpoint(\n",
        "                        'fnn_model.hdf5',\n",
        "                        verbose=1,\n",
        "                        save_best_only=True,\n",
        "                        monitor='val_loss')\n",
        "        X_train, X_test = X_train_scaled[train_index], X_train_scaled[test_index]\n",
        "        Y_train, Y_test = y_train[train_index], y_train[test_index]\n",
        "        main_model = build_model(batch_size)\n",
        "        main_model.summary()\n",
        "        hist = main_model.fit(x=X_train,\n",
        "                              y=Y_train,\n",
        "                              validation_data=(X_test, Y_test),\n",
        "                              epochs=100,\n",
        "                              verbose=0,\n",
        "                              callbacks=[stop_early, checkpoint, time])\n",
        "\n",
        "        accuracies2a.append(hist.history['accuracy'][-1])\n",
        "        training_times2a.append(time.logs[-1])\n",
        "        tf.keras.backend.clear_session()\n",
        "    accuracy_dict2a[f'{batch_size}'] = accuracies2a\n",
        "    time_dict2a[f'{batch_size}'] = training_times2a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmqVZfLD31zI",
        "outputId": "519d49dd-08c6-43ae-ce71-9090122a0b28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_16 (Dense)            (None, 64)                4992      \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,377\n",
            "Trainable params: 13,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.68178, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 2: val_loss improved from 0.68178 to 0.67780, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 3: val_loss improved from 0.67780 to 0.67403, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 4: val_loss improved from 0.67403 to 0.66431, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 5: val_loss improved from 0.66431 to 0.66259, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 6: val_loss improved from 0.66259 to 0.66078, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 7: val_loss improved from 0.66078 to 0.65470, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.65470\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.65470\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.65470\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 64)                4992      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,377\n",
            "Trainable params: 13,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.68104, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 2: val_loss improved from 0.68104 to 0.67708, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.67708\n",
            "\n",
            "Epoch 4: val_loss improved from 0.67708 to 0.67363, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 5: val_loss improved from 0.67363 to 0.66723, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 6: val_loss improved from 0.66723 to 0.66289, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 7: val_loss improved from 0.66289 to 0.66168, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 8: val_loss improved from 0.66168 to 0.65771, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 9: val_loss improved from 0.65771 to 0.65746, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.65746\n",
            "\n",
            "Epoch 11: val_loss improved from 0.65746 to 0.64979, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.64979\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.64979\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.64979\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 64)                4992      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,377\n",
            "Trainable params: 13,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.68094, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 2: val_loss improved from 0.68094 to 0.67900, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 3: val_loss improved from 0.67900 to 0.67447, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 4: val_loss improved from 0.67447 to 0.66956, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 5: val_loss improved from 0.66956 to 0.66437, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 6: val_loss improved from 0.66437 to 0.66300, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 7: val_loss improved from 0.66300 to 0.66255, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 8: val_loss improved from 0.66255 to 0.66064, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.66064\n",
            "\n",
            "Epoch 10: val_loss improved from 0.66064 to 0.64996, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.64996\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.64996\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.64996\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 64)                4992      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,377\n",
            "Trainable params: 13,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.68274, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 2: val_loss improved from 0.68274 to 0.67990, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 3: val_loss improved from 0.67990 to 0.67430, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 4: val_loss improved from 0.67430 to 0.66840, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 5: val_loss improved from 0.66840 to 0.66629, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 6: val_loss improved from 0.66629 to 0.66486, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 7: val_loss improved from 0.66486 to 0.66245, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 8: val_loss improved from 0.66245 to 0.65981, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.65981\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.65981\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.65981\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 64)                4992      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,377\n",
            "Trainable params: 13,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.68177, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 2: val_loss improved from 0.68177 to 0.67720, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 3: val_loss improved from 0.67720 to 0.67028, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 4: val_loss improved from 0.67028 to 0.66954, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 5: val_loss improved from 0.66954 to 0.65893, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.65893\n",
            "\n",
            "Epoch 7: val_loss improved from 0.65893 to 0.65297, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.65297\n",
            "\n",
            "Epoch 9: val_loss improved from 0.65297 to 0.64835, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.64835\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.64835\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.64835\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 64)                4992      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,377\n",
            "Trainable params: 13,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.68190, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 2: val_loss improved from 0.68190 to 0.67864, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 3: val_loss improved from 0.67864 to 0.67589, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 4: val_loss improved from 0.67589 to 0.66916, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 5: val_loss improved from 0.66916 to 0.66442, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.66442\n",
            "\n",
            "Epoch 7: val_loss improved from 0.66442 to 0.65608, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.65608\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.65608\n",
            "\n",
            "Epoch 10: val_loss improved from 0.65608 to 0.65235, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.65235\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.65235\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.65235\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 64)                4992      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,377\n",
            "Trainable params: 13,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.68111, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 2: val_loss improved from 0.68111 to 0.67680, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 3: val_loss improved from 0.67680 to 0.67416, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 4: val_loss improved from 0.67416 to 0.66651, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 5: val_loss improved from 0.66651 to 0.66066, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 6: val_loss improved from 0.66066 to 0.65991, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 7: val_loss improved from 0.65991 to 0.65661, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.65661\n",
            "\n",
            "Epoch 9: val_loss improved from 0.65661 to 0.65542, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.65542\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.65542\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.65542\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 64)                4992      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,377\n",
            "Trainable params: 13,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.68344, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 2: val_loss improved from 0.68344 to 0.67929, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 3: val_loss improved from 0.67929 to 0.67652, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 4: val_loss improved from 0.67652 to 0.67400, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 5: val_loss improved from 0.67400 to 0.66810, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.66810\n",
            "\n",
            "Epoch 7: val_loss improved from 0.66810 to 0.66174, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.66174\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.66174\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.66174\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 64)                4992      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,377\n",
            "Trainable params: 13,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.68260, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 2: val_loss improved from 0.68260 to 0.67986, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 3: val_loss improved from 0.67986 to 0.67473, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 4: val_loss improved from 0.67473 to 0.67044, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 5: val_loss improved from 0.67044 to 0.66732, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 6: val_loss improved from 0.66732 to 0.66462, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 7: val_loss improved from 0.66462 to 0.66349, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 8: val_loss improved from 0.66349 to 0.65743, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.65743\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.65743\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.65743\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 64)                4992      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,377\n",
            "Trainable params: 13,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.68239, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 2: val_loss improved from 0.68239 to 0.67964, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 3: val_loss improved from 0.67964 to 0.67245, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 4: val_loss improved from 0.67245 to 0.67130, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 5: val_loss improved from 0.67130 to 0.66189, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.66189\n",
            "\n",
            "Epoch 7: val_loss improved from 0.66189 to 0.65777, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 8: val_loss improved from 0.65777 to 0.65620, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 9: val_loss improved from 0.65620 to 0.65471, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.65471\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.65471\n",
            "\n",
            "Epoch 12: val_loss improved from 0.65471 to 0.65430, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.65430\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.65430\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.65430\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 64)                4992      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,377\n",
            "Trainable params: 13,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.68204, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 2: val_loss improved from 0.68204 to 0.67997, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 3: val_loss improved from 0.67997 to 0.67564, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 4: val_loss improved from 0.67564 to 0.66740, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.66740\n",
            "\n",
            "Epoch 6: val_loss improved from 0.66740 to 0.66114, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 7: val_loss improved from 0.66114 to 0.66030, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.66030\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.66030\n",
            "\n",
            "Epoch 10: val_loss improved from 0.66030 to 0.65578, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 11: val_loss improved from 0.65578 to 0.65548, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.65548\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.65548\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.65548\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 64)                4992      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,377\n",
            "Trainable params: 13,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.68005, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 2: val_loss improved from 0.68005 to 0.67552, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 3: val_loss improved from 0.67552 to 0.67333, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 4: val_loss improved from 0.67333 to 0.66894, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 5: val_loss improved from 0.66894 to 0.66337, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 6: val_loss improved from 0.66337 to 0.65940, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 7: val_loss improved from 0.65940 to 0.65571, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 8: val_loss improved from 0.65571 to 0.65480, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.65480\n",
            "\n",
            "Epoch 10: val_loss improved from 0.65480 to 0.65136, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.65136\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.65136\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.65136\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 64)                4992      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,377\n",
            "Trainable params: 13,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.68163, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 2: val_loss improved from 0.68163 to 0.67876, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 3: val_loss improved from 0.67876 to 0.67630, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 4: val_loss improved from 0.67630 to 0.67222, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 5: val_loss improved from 0.67222 to 0.66735, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.66735\n",
            "\n",
            "Epoch 7: val_loss improved from 0.66735 to 0.66065, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 8: val_loss improved from 0.66065 to 0.65746, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.65746\n",
            "\n",
            "Epoch 10: val_loss improved from 0.65746 to 0.65685, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.65685\n",
            "\n",
            "Epoch 12: val_loss improved from 0.65685 to 0.65075, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.65075\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.65075\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.65075\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 64)                4992      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,377\n",
            "Trainable params: 13,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.68206, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 2: val_loss improved from 0.68206 to 0.68071, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 3: val_loss improved from 0.68071 to 0.67285, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 4: val_loss improved from 0.67285 to 0.67006, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 5: val_loss improved from 0.67006 to 0.66737, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 6: val_loss improved from 0.66737 to 0.66500, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 7: val_loss improved from 0.66500 to 0.66284, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.66284\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.66284\n",
            "\n",
            "Epoch 10: val_loss improved from 0.66284 to 0.65496, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.65496\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.65496\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.65496\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 64)                4992      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,377\n",
            "Trainable params: 13,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.68146, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 2: val_loss improved from 0.68146 to 0.67946, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 3: val_loss improved from 0.67946 to 0.67253, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 4: val_loss improved from 0.67253 to 0.67111, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 5: val_loss improved from 0.67111 to 0.66488, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.66488\n",
            "\n",
            "Epoch 7: val_loss improved from 0.66488 to 0.65843, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.65843\n",
            "\n",
            "Epoch 9: val_loss improved from 0.65843 to 0.65362, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.65362\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.65362\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.65362\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 64)                4992      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,377\n",
            "Trainable params: 13,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.68204, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 2: val_loss improved from 0.68204 to 0.67837, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 3: val_loss improved from 0.67837 to 0.67714, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 4: val_loss improved from 0.67714 to 0.67068, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 5: val_loss improved from 0.67068 to 0.67008, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 6: val_loss improved from 0.67008 to 0.66830, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 7: val_loss improved from 0.66830 to 0.66150, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.66150\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.66150\n",
            "\n",
            "Epoch 10: val_loss improved from 0.66150 to 0.65617, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 11: val_loss improved from 0.65617 to 0.65501, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.65501\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.65501\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.65501\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 64)                4992      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,377\n",
            "Trainable params: 13,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.68034, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 2: val_loss improved from 0.68034 to 0.67407, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 3: val_loss improved from 0.67407 to 0.67097, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 4: val_loss improved from 0.67097 to 0.66643, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 5: val_loss improved from 0.66643 to 0.66031, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 6: val_loss improved from 0.66031 to 0.65805, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.65805\n",
            "\n",
            "Epoch 8: val_loss improved from 0.65805 to 0.65473, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.65473\n",
            "\n",
            "Epoch 10: val_loss improved from 0.65473 to 0.65381, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.65381\n",
            "\n",
            "Epoch 12: val_loss improved from 0.65381 to 0.65315, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.65315\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.65315\n",
            "\n",
            "Epoch 15: val_loss improved from 0.65315 to 0.64810, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.64810\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.64810\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.64810\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 64)                4992      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,377\n",
            "Trainable params: 13,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.68183, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 2: val_loss improved from 0.68183 to 0.67629, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 3: val_loss improved from 0.67629 to 0.67377, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 4: val_loss improved from 0.67377 to 0.66873, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 5: val_loss improved from 0.66873 to 0.66165, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.66165\n",
            "\n",
            "Epoch 7: val_loss improved from 0.66165 to 0.65569, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.65569\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.65569\n",
            "\n",
            "Epoch 10: val_loss improved from 0.65569 to 0.65511, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.65511\n",
            "\n",
            "Epoch 12: val_loss improved from 0.65511 to 0.64948, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.64948\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.64948\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.64948\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 64)                4992      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,377\n",
            "Trainable params: 13,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.68321, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 2: val_loss improved from 0.68321 to 0.67877, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 3: val_loss improved from 0.67877 to 0.67515, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 4: val_loss improved from 0.67515 to 0.66834, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 5: val_loss improved from 0.66834 to 0.66418, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.66418\n",
            "\n",
            "Epoch 7: val_loss improved from 0.66418 to 0.65895, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 8: val_loss improved from 0.65895 to 0.65846, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 9: val_loss improved from 0.65846 to 0.65755, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.65755\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.65755\n",
            "\n",
            "Epoch 12: val_loss improved from 0.65755 to 0.65722, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 13: val_loss improved from 0.65722 to 0.65594, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.65594\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.65594\n",
            "\n",
            "Epoch 16: val_loss improved from 0.65594 to 0.65521, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.65521\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.65521\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.65521\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 64)                4992      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,377\n",
            "Trainable params: 13,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.68155, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 2: val_loss improved from 0.68155 to 0.68052, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 3: val_loss improved from 0.68052 to 0.67338, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 4: val_loss improved from 0.67338 to 0.67115, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 5: val_loss improved from 0.67115 to 0.66724, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 6: val_loss improved from 0.66724 to 0.66614, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 7: val_loss improved from 0.66614 to 0.65971, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.65971\n",
            "\n",
            "Epoch 9: val_loss improved from 0.65971 to 0.65617, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.65617\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.65617\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.65617\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Qn 2**\n",
        "b. Create a table of time taken to train the network on the last epoch against different batch sizes."
      ],
      "metadata": {
        "id": "SUZ1_R0NXojf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "time_dict2a"
      ],
      "metadata": {
        "id": "b21YEJ7UPdfI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b90df553-cd26-4d4a-8f20-94cfd13479e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'128': [6.241160135999962,\n",
              "  6.219075796999732,\n",
              "  6.665819216999807,\n",
              "  6.201456933999907,\n",
              "  6.536456800999986],\n",
              " '256': [6.2547914599999785,\n",
              "  6.582779055999708,\n",
              "  6.538427198000136,\n",
              "  6.300850395999987,\n",
              "  6.140822520999791],\n",
              " '512': [6.251279808000618,\n",
              "  6.24473961700005,\n",
              "  6.162585670000226,\n",
              "  6.66569950199937,\n",
              "  6.2778524109999125],\n",
              " '1024': [6.565698623000571,\n",
              "  6.546746140000323,\n",
              "  6.569552668000142,\n",
              "  8.043977783999253,\n",
              "  6.530082719999882]}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Qn 2**\n",
        "c. Select the optimal batch size and state a reason for your selection."
      ],
      "metadata": {
        "id": "Qd8fY-xpyfAe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_dict2a"
      ],
      "metadata": {
        "id": "BJ8tmPSdPYNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae12a9ef-dc26-4a99-e25d-81bfe2a89d23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'128': [0.6605559587478638,\n",
              "  0.6843260526657104,\n",
              "  0.6754423975944519,\n",
              "  0.6675844192504883,\n",
              "  0.6729341149330139],\n",
              " '256': [0.6777417659759521,\n",
              "  0.6763896346092224,\n",
              "  0.6562775373458862,\n",
              "  0.6654484272003174,\n",
              "  0.687993586063385],\n",
              " '512': [0.6798385381698608,\n",
              "  0.6771930456161499,\n",
              "  0.6852403283119202,\n",
              "  0.6825655102729797,\n",
              "  0.6705139875411987],\n",
              " '1024': [0.6826211810112,\n",
              "  0.7021977305412292,\n",
              "  0.6882287263870239,\n",
              "  0.7037976980209351,\n",
              "  0.6681820750236511]}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Batch size = 128, would be the optimal batch size, because it gives the highest accuracy."
      ],
      "metadata": {
        "id": "n-4f3ZKIaQRV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Qn 2**\n",
        "d. What happens when batch sizes increases & why?"
      ],
      "metadata": {
        "id": "9gOIBRZJyuFb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The accuracy increases as the batch size increase, because, bigger batch size has less noise, and it offers better convergence as compared to a smaller batch size, but it is slower."
      ],
      "metadata": {
        "id": "pj_cNecGayi3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Qn 2**\n",
        "e. Plot the train & test accuracies against epoch for the optimal batch size in a line plot."
      ],
      "metadata": {
        "id": "NsE1Q1NPymoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimal_bs=[128, 256, 512, 1024]\n",
        "accuracies2e=[0.7413605451583862, 0.7459558248519897, 0.7445743083953857, 0.7578334808349609]\n",
        "plt.plot(optimal_bs, accuracies2e)\n",
        "plt.title('Qn2e')\n",
        "plt.show"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "vx6W2FpMzUlz",
        "outputId": "d50d2e56-0b8f-49ab-fd6c-6ed4e663698d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show(*args, **kw)>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Qn 3**\n",
        "a. Plot the mean cross-validation accuracies on the final epoch for different numbers of hidden-layer usin g a scatter plot. Limit the search space of the number of neurons to {64, 128, 256}.\n",
        "\n",
        "Continue using the 5-fold cross validation on the training set."
      ],
      "metadata": {
        "id": "ra4tMtIi1EL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(hidden_layer):\n",
        "  ffn = models.Sequential()\n",
        "  ffn.add(layers.Dense(units=hidden_layer, activation='relu', input_shape=(77,)))\n",
        "  ffn.add(layers.Dense(units=hidden_layer, activation='relu'))\n",
        "  ffn.add(layers.Dense(units=hidden_layer, activation='relu'))\n",
        "  ffn.add(layers.Dense(units=1, activation='sigmoid'))\n",
        "  opt=optimizers.Adam()\n",
        "  ffn.compile(\n",
        "      optimizer=opt,\n",
        "      loss='BinaryCrossentropy',\n",
        "      metrics=['accuracy']\n",
        "  )\n",
        "\n",
        "  return ffn"
      ],
      "metadata": {
        "id": "VlU96ly_Nenx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_layer_list3a=[64, 128, 256]\n",
        "accuracy_dict3a={}\n",
        "time_dict3a={}\n",
        "\n",
        "for hidden_layer in hidden_layer_list3a:\n",
        "    kfold = KFold(n_splits=5)\n",
        "    accuracies3a = []\n",
        "    training_times3a = []\n",
        "    for train_index, test_index in kfold.split(X_train_scaled):\n",
        "        stop_early = callbacks.EarlyStopping(\n",
        "                            monitor='val_loss', patience=3)\n",
        "        checkpoint = callbacks.ModelCheckpoint(\n",
        "                        'fnn_model.hdf5',\n",
        "                        verbose=1,\n",
        "                        save_best_only=True,\n",
        "                        monitor='val_loss')\n",
        "        X_train, X_test = X_train_scaled[train_index], X_train_scaled[test_index]\n",
        "        Y_train, Y_test = y_train[train_index], y_train[test_index]\n",
        "        main_model = build_model(hidden_layer)\n",
        "        main_model.summary()\n",
        "        hist = main_model.fit(x=X_train,\n",
        "                              y=Y_train,\n",
        "                              validation_data=(X_test, Y_test),\n",
        "                              epochs=100,\n",
        "                              verbose=0,\n",
        "                              callbacks=[stop_early, checkpoint, time])\n",
        "\n",
        "        accuracies3a.append(hist.history['accuracy'][-1])\n",
        "        training_times3a.append(time.logs[-1])\n",
        "        tf.keras.backend.clear_session()\n",
        "    accuracy_dict3a[f'{hidden_layer}'] = accuracies3a\n",
        "    time_dict3a[f'{hidden_layer}'] = training_times3a"
      ],
      "metadata": {
        "id": "UVFYI4mTOBkJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a44e6db-bd54-4bbb-b486-f9199ad8f287"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 64)                4992      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,377\n",
            "Trainable params: 13,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.68239, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 2: val_loss improved from 0.68239 to 0.68087, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 3: val_loss improved from 0.68087 to 0.67716, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 4: val_loss improved from 0.67716 to 0.66973, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 5: val_loss improved from 0.66973 to 0.66625, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.66625\n",
            "\n",
            "Epoch 7: val_loss improved from 0.66625 to 0.65836, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.65836\n",
            "\n",
            "Epoch 9: val_loss improved from 0.65836 to 0.65595, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 10: val_loss improved from 0.65595 to 0.65070, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.65070\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.65070\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.65070\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 64)                4992      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,377\n",
            "Trainable params: 13,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.68061, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 2: val_loss improved from 0.68061 to 0.67675, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 3: val_loss improved from 0.67675 to 0.67321, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 4: val_loss improved from 0.67321 to 0.66829, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 5: val_loss improved from 0.66829 to 0.66292, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 6: val_loss improved from 0.66292 to 0.66052, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.66052\n",
            "\n",
            "Epoch 8: val_loss improved from 0.66052 to 0.66037, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 9: val_loss improved from 0.66037 to 0.65885, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 10: val_loss improved from 0.65885 to 0.65432, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.65432\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.65432\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.65432\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 64)                4992      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,377\n",
            "Trainable params: 13,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.68260, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 2: val_loss improved from 0.68260 to 0.67736, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 3: val_loss improved from 0.67736 to 0.67381, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 4: val_loss improved from 0.67381 to 0.66860, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 5: val_loss improved from 0.66860 to 0.66539, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 6: val_loss improved from 0.66539 to 0.66113, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 7: val_loss improved from 0.66113 to 0.65891, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 8: val_loss improved from 0.65891 to 0.65714, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.65714\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.65714\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.65714\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 64)                4992      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,377\n",
            "Trainable params: 13,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.68265, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 2: val_loss improved from 0.68265 to 0.68203, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 3: val_loss improved from 0.68203 to 0.67277, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 4: val_loss improved from 0.67277 to 0.66779, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 5: val_loss improved from 0.66779 to 0.66357, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 6: val_loss improved from 0.66357 to 0.66254, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 7: val_loss improved from 0.66254 to 0.65862, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.65862\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.65862\n",
            "\n",
            "Epoch 10: val_loss improved from 0.65862 to 0.65822, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.65822\n",
            "\n",
            "Epoch 12: val_loss improved from 0.65822 to 0.65678, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.65678\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.65678\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.65678\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 64)                4992      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,377\n",
            "Trainable params: 13,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.68217, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 2: val_loss improved from 0.68217 to 0.67884, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 3: val_loss improved from 0.67884 to 0.67367, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 4: val_loss improved from 0.67367 to 0.66889, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 5: val_loss improved from 0.66889 to 0.66515, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.66515\n",
            "\n",
            "Epoch 7: val_loss improved from 0.66515 to 0.65816, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.65816\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.65816\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.65816\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 128)               9984      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 43,137\n",
            "Trainable params: 43,137\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.68050, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 2: val_loss improved from 0.68050 to 0.67806, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 3: val_loss improved from 0.67806 to 0.67051, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 4: val_loss improved from 0.67051 to 0.65849, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 5: val_loss improved from 0.65849 to 0.65652, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 6: val_loss improved from 0.65652 to 0.65455, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 7: val_loss improved from 0.65455 to 0.64851, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.64851\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.64851\n",
            "\n",
            "Epoch 10: val_loss improved from 0.64851 to 0.64341, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 11: val_loss improved from 0.64341 to 0.63960, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.63960\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.63960\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.63960\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 128)               9984      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 43,137\n",
            "Trainable params: 43,137\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.68021, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 2: val_loss improved from 0.68021 to 0.67480, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 3: val_loss improved from 0.67480 to 0.67078, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 4: val_loss improved from 0.67078 to 0.66200, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 5: val_loss improved from 0.66200 to 0.65479, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 6: val_loss improved from 0.65479 to 0.65349, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 7: val_loss improved from 0.65349 to 0.65326, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 8: val_loss improved from 0.65326 to 0.64854, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 9: val_loss improved from 0.64854 to 0.64695, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 10: val_loss improved from 0.64695 to 0.64180, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 11: val_loss improved from 0.64180 to 0.63695, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.63695\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.63695\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.63695\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 128)               9984      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 43,137\n",
            "Trainable params: 43,137\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.68067, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 2: val_loss improved from 0.68067 to 0.67563, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 3: val_loss improved from 0.67563 to 0.67076, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 4: val_loss improved from 0.67076 to 0.66024, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 5: val_loss improved from 0.66024 to 0.65100, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 6: val_loss improved from 0.65100 to 0.64884, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 7: val_loss improved from 0.64884 to 0.64079, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 8: val_loss improved from 0.64079 to 0.63919, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.63919\n",
            "\n",
            "Epoch 10: val_loss improved from 0.63919 to 0.63562, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.63562\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.63562\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.63562\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 128)               9984      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 43,137\n",
            "Trainable params: 43,137\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.68234, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 2: val_loss improved from 0.68234 to 0.67965, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 3: val_loss improved from 0.67965 to 0.66770, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 4: val_loss improved from 0.66770 to 0.66178, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 5: val_loss improved from 0.66178 to 0.65352, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.65352\n",
            "\n",
            "Epoch 7: val_loss improved from 0.65352 to 0.64746, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.64746\n",
            "\n",
            "Epoch 9: val_loss improved from 0.64746 to 0.64221, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.64221\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.64221\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.64221\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 128)               9984      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 43,137\n",
            "Trainable params: 43,137\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.68201, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 2: val_loss improved from 0.68201 to 0.68174, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 3: val_loss improved from 0.68174 to 0.66942, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 4: val_loss improved from 0.66942 to 0.66423, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 5: val_loss improved from 0.66423 to 0.65257, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.65257\n",
            "\n",
            "Epoch 7: val_loss improved from 0.65257 to 0.63888, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.63888\n",
            "\n",
            "Epoch 9: val_loss improved from 0.63888 to 0.63855, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 10: val_loss improved from 0.63855 to 0.63519, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.63519\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.63519\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.63519\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 256)               19968     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 151,809\n",
            "Trainable params: 151,809\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.68346, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 2: val_loss improved from 0.68346 to 0.68023, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 3: val_loss improved from 0.68023 to 0.67222, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 4: val_loss improved from 0.67222 to 0.66107, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 5: val_loss improved from 0.66107 to 0.65496, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 6: val_loss improved from 0.65496 to 0.64302, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 7: val_loss improved from 0.64302 to 0.64135, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.64135\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.64135\n",
            "\n",
            "Epoch 10: val_loss improved from 0.64135 to 0.62656, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.62656\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.62656\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.62656\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 256)               19968     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 151,809\n",
            "Trainable params: 151,809\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.68050, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 2: val_loss improved from 0.68050 to 0.67592, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 3: val_loss improved from 0.67592 to 0.67163, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 4: val_loss improved from 0.67163 to 0.65915, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 5: val_loss improved from 0.65915 to 0.65062, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 6: val_loss improved from 0.65062 to 0.64418, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 7: val_loss improved from 0.64418 to 0.64235, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 8: val_loss improved from 0.64235 to 0.63698, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 9: val_loss improved from 0.63698 to 0.63539, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.63539\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.63539\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.63539\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 256)               19968     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 151,809\n",
            "Trainable params: 151,809\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.68071, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 2: val_loss improved from 0.68071 to 0.67710, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 3: val_loss improved from 0.67710 to 0.67060, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 4: val_loss improved from 0.67060 to 0.66346, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 5: val_loss improved from 0.66346 to 0.64808, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 6: val_loss improved from 0.64808 to 0.64390, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 7: val_loss improved from 0.64390 to 0.63308, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.63308\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.63308\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.63308\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 256)               19968     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 151,809\n",
            "Trainable params: 151,809\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.68227, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 2: val_loss improved from 0.68227 to 0.67817, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 3: val_loss improved from 0.67817 to 0.66943, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 4: val_loss improved from 0.66943 to 0.66016, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 5: val_loss improved from 0.66016 to 0.64815, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.64815\n",
            "\n",
            "Epoch 7: val_loss improved from 0.64815 to 0.63943, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.63943\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.63943\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.63943\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 256)               19968     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 151,809\n",
            "Trainable params: 151,809\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.68218, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 2: val_loss improved from 0.68218 to 0.67970, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 3: val_loss improved from 0.67970 to 0.66560, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 4: val_loss improved from 0.66560 to 0.65696, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 5: val_loss improved from 0.65696 to 0.64789, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 6: val_loss improved from 0.64789 to 0.64343, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 7: val_loss improved from 0.64343 to 0.63114, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 8: val_loss improved from 0.63114 to 0.62814, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 9: val_loss improved from 0.62814 to 0.62146, saving model to fnn_model.hdf5\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.62146\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.62146\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.62146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Qn 3**\n",
        "b. Select the optimal number of neuron for the hidden layer. State the rationale for your selection."
      ],
      "metadata": {
        "id": "Cqm7WDjp1sAY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_dict3a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bopqQgf6Fftu",
        "outputId": "dca93416-0399-470c-b93a-1baa88786f90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'64': [0.6775751709938049,\n",
              "  0.6781434416770935,\n",
              "  0.6674766540527344,\n",
              "  0.6852011680603027,\n",
              "  0.6537497043609619],\n",
              " '128': [0.7470826506614685,\n",
              "  0.7435651421546936,\n",
              "  0.7459877133369446,\n",
              "  0.7295859456062317,\n",
              "  0.7344555258750916],\n",
              " '256': [0.7845112085342407,\n",
              "  0.7755950093269348,\n",
              "  0.7352883815765381,\n",
              "  0.7352393865585327,\n",
              "  0.7705610394477844]}"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "time_dict3a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUte2ZA6Fk1p",
        "outputId": "0f7b4e2d-2a32-4652-d214-5c8c20c02118"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'64': [6.109505286000058,\n",
              "  6.608463904999553,\n",
              "  6.385693682999772,\n",
              "  6.603643895999994,\n",
              "  6.30213061700033],\n",
              " '128': [7.124527683999986,\n",
              "  7.365507186000286,\n",
              "  7.006144352999399,\n",
              "  7.347017142999903,\n",
              "  7.262694633000137],\n",
              " '256': [9.955329811999945,\n",
              "  10.215213648999452,\n",
              "  10.449435098999857,\n",
              "  10.345238585000516,\n",
              "  10.485745285000121]}"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "256 would the most the most optimal number of neurons for the hidden layer, because even tough 128 has the highest accuracy, but if we factor in the time taken as well as accuracy, it would be more optimal to select 256."
      ],
      "metadata": {
        "id": "raxx08xMdT4S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Qn 3**\n",
        "c. Plot the train and test accuracies against the training epochs with the optimal number of neurons using a line plot."
      ],
      "metadata": {
        "id": "BBfXq85e2CLI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(hist.history['accuracy'])\n",
        "plt.plot(hist.history['val_accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "LI7Jl3M1GC_L",
        "outputId": "001b82cf-7679-4ddb-f296-36a6e18d0bbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f1a8cf78510>]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3hUVf7H8fchIZRQQ0JLCDX0zlAEV1Es6CqoWBB1sWJZ+7prWde69rXgTxRZBbHBKiCCIqAiuiILJFJCCRBCS2ghCYH0dn5/3GEJbJAAk9zJ5PN6njzJ3Hvu5DsQPrmcc+d7jbUWEREJXDXcLkBERCqWgl5EJMAp6EVEApyCXkQkwCnoRUQCXLDbBRwrPDzctmnTxu0yRESqlLi4uP3W2oiy9vld0Ldp04bY2Fi3yxARqVKMMduPt09TNyIiAU5BLyIS4BT0IiIBTkEvIhLgFPQiIgFOQS8iEuAU9CIiAU5BLyLisuISy1drdjFt+Y4KeX6/e8OUiEh1UVhcwhcrU5i4eAtJ+7PpG92I0f1bYYzx6fdR0IuIVLK8wmI+i93Juz8mkXIgl64tGvD2dX25sFtzn4c8KOhFRCpNdn4RnyzbzqSftrI/K59+rRvz98u6M7RTRIUE/GEKehGRCpaZU8gHv2xjyi9bOZBTyJkdwvnjOX0Y1C6sQgP+MAW9iEgFST2Uz/s/b+Xj/2wnK7+I87o044/ntKdPdONKrUNBLyLiY7sO5DLppySmLd9BQXEJl/RsyV1D29OlRQNX6lHQi4j4yLb92byzeAuzViZjLVzeJ5I7h7anXUQ9V+tS0IuInKaNew4x4YdEvlqzi5pBNRgzIJpxZ7cnslEdt0sDFPQiIqds9c4DvPVDIt+u30toSBC3ndWOW85sS9P6td0u7SgKehGRk2CtZdnWdCb8kMi/N++nYZ2a3H9eDDcObkOjuiFul1cmBb2ISDlYa1m8KZUJixKJ3Z5BeL1aPHJRZ64f1Jp6tfw7Sv27OhERl5WUWBas28OExYmsTTlIy4a1eXpEN67p34raNYPcLq9cFPQiImUoKi5hzupdvL14C4n7smgbHsrLo3pyWZ9IQoKrVj9IBb2ISCn5RcXMiEtm4o9b2JmeS+fm9Xnz2j78vkcLgmpU/LtYK4KCXkQEyCko4tNlO/jnv5PYezCfXq0a8cQl3RjWuSk1qmjAH1auoDfGDAfGA0HAe9baF4/Z/zpwjvdhXaCptbaRd18xEO/dt8NaO8IXhYuI+EJmbiEf/rKNyUu2kpFTyBntmvDa1b0Z3L5JpfShqQwnDHpjTBAwATgfSAZWGGPmWGvXHx5jrX2g1Ph7gD6lniLXWtvbdyWLiJy+tCynD81HS7dzKL+Iczs35Y/ndKBf68rtQ1MZynNGPwBItNYmARhjpgMjgfXHGX8t8KRvyhMR8a3dmUf60OQXlXBx9xbcdU57urVs6HZpFaY8QR8J7Cz1OBkYWNZAY0xroC2wqNTm2saYWKAIeNFaO7uM48YB4wCio6PLV7mIyEnYnpbNxB+3MCMumRILl/V2+tB0aOpuH5rK4OvF2NHADGttcaltra21KcaYdsAiY0y8tXZL6YOstZOASQAej8f6uCYRqcY27XX60MxdvYvgoBqM7h/NuLPa0SqsrtulVZryBH0K0KrU4yjvtrKMBv5YeoO1NsX7OckYsxhn/n7L/x4qIuI7a5IP8NaiRBau30vdkCBu/V07bj2zLU0b+FcfmspQnqBfAcQYY9riBPxoYMyxg4wxnYHGwNJS2xoDOdbafGNMODAEeNkXhYuIlGVZUhpvefvQNKgdzL3DYrhpcBsah/pnH5rKcMKgt9YWGWPuBhbgXF452Vq7zhjzDBBrrZ3jHToamG6tLT310gV41xhTAtTAmaM/3iKuiMgpOdyH5u0fElmxLYPweiE8PLwz1w+Kpn7tmm6X5zpzdC67z+Px2NjYWLfLEJEqoKw+NOPOasfoAdFVpg+Nrxhj4qy1nrL26Z2xIlLlBFIfmsqgoBeRKiMQ+9BUBgW9iPg9ay1fx+/mua83sDszL6D60FQGBb2I+LWt+7N54su1/Hvzfrq1bMArV/ZiSIfA6UNTGRT0IuKX8gqLeXvxFiYu3kKt4Bo8dWlXrh/UmuAgzcGfLAW9iPidHzbu46k569ielsPI3i3568VdquUbnXxFQS8ifmPXgVye/Wo936zdQ7uIUD69dSCDO4S7XVaVp6AXEdcVFpcwZclW3vhuM8Ullj9f2Ilbf9eWWsHV61r4iqKgFxFXrdiWzuNfrGXj3kMM69yUp0Z0q1YNxyqDgl5EXJGWlc8L3yQwIy6ZyEZ1mHRDPy7o1tztsgKSgl5EKlVJiWX6ip28ND+B7Pwi7hzannvO7UDdEMVRRdGfrIhUmrUpmfx19lpW7zzAoHZhPDuyOzHN6rtdVsBT0ItIhTuYV8hrCzfx4dJthIWG8Po1vbisd6Te9FRJFPQiUmGstcxZvYu/f72B/Vn53DCoNX+6oBMN66h1cGVS0ItIhdiSmsUTX65lSWIaPaMa8v5YDz2jGrldVrWkoBcRn8otKGbCD4m8+9MWatcM4tnLujNmQLS6S7pIQS8iPvP9hr08OWcdyRm5XNE3kkcv6kJE/Vpul1XtKehF5LQlZ+TwzNz1LFy/l5im9Zg+bhCD2jVxuyzxUtCLyCkrKCrh/Z+38ub3mwF45KLO3Dykre7y5GcU9CJySlZsS+exWfFs3pfFhd2a8cSl3YhsVMftsqQMCnoROSmZOYW8OH8D05bvJLJRHd4f62FYl2ZulyW/QUEvIuVy+Jr4Z79aT0ZOIePOasf958WodUEVoL8hETmh7WnZPD7buZ1fr1aNmHpzd7q1bOh2WVJOCnoROa6CohL++e8k3vx+MzWDavDMyG5cN7C1romvYhT0IlKm2G3pPPZFPJv2ZnFxj+Y8eWk3mul2flWSgl5EjuIstiYwbfkOLbYGCAW9iABabA1k+hsUkaMXW6MaMvXmAVpsDSAKepFq7NjF1qdHdOP6QVpsDTQKepFqKm57Oo/Ncm7KfVF3Z7G1eUMttgYiBb1INZOZU8hLCxL4dJmz2PreHzyc11WLrYFMQS9STVhrmbtmN8/MXU96dj63/a4t95/XkdBaioFAp79hkWpgR1oOj3+5lp82pdIrqiEf3NSf7pFabK0uFPQiAayw2FlsHf+ds9j61KVdueGMNlpsrWYU9CIBqvRi6/BuzXlyRFdaNFQb4eqoXHcHMMYMN8ZsNMYkGmMeKWP/68aYVd6PTcaYA6X2jTXGbPZ+jPVl8SLyvzJzC/nrF/GMemcph/IK+ecfPEy8oZ9Cvho74Rm9MSYImACcDyQDK4wxc6y16w+PsdY+UGr8PUAf79dhwJOAB7BAnPfYDJ++ChHBWsu8+D08OWcd6dn53HpmWx44X4utUr6pmwFAorU2CcAYMx0YCaw/zvhrccId4ELgW2ttuvfYb4HhwLTTKVpEjrb3YB5/m72Whev30j2ygRZb5SjlCfpIYGepx8nAwLIGGmNaA22BRb9xbOTJlykiZbHW8lnsTv7+9QYKikp49KLO3HJmW4KDdM9WOcLX/6cbDcyw1hafzEHGmHHAOIDo6GgflyQSmHak5fDoF2tYkpjGwLZhvDiqJ23DQ90uS/xQeYI+BWhV6nGUd1tZRgN/PObYocccu/jYg6y1k4BJAB6Px5ajJpFqq7jEMmXJVl5duImgGobnLu/Otf2jqaFLJuU4yhP0K4AYY0xbnOAeDYw5dpAxpjPQGFhaavMC4HljTGPv4wuAR0+rYpFqbOOeQzw8cw2rdh7g3M5Nee7y7rqaRk7ohEFvrS0yxtyNE9pBwGRr7TpjzDNArLV2jnfoaGC6tdaWOjbdGPMszi8LgGcOL8yKSPkVFJXw9uJEJvyQSP3aNRk/ujcjerXEGJ3Fy4mZUrnsFzwej42NjXW7DBG/sWrnAR6esYaNew8xsndLnrikK03q1XK7LPEzxpg4a62nrH26wFbET+UWFPPqwo1MXrKVpvVr65Z+csoU9CJ+6JfE/TwyK54d6TlcNzCaRy7qTP3aNd0uS6ooBb2IH8nMLeSFeRuYvmInbcNDmT5uEIPaNXG7LKniFPQifmLhuj08Pnst+7Pyuf3sdjxwXkdq1wxyuywJAAp6EZelHsrnqbnr+HrNbjo3r897Yz30jGrkdlkSQBT0Ii6x1vLFyhSe+Wo9OfnFPHRBR24/uz011b5AfExBL+KClAO5PDYrnh83pdKvdWNeGtWDDk3ru12WBCgFvUglKimxfLxsOy99k4AFnh7RjRsGtVb7AqlQCnqRSrIlNYtHZq5hxbYMzuoYwfOXdyeqcV23y5JqQEEvUsEKi0uY9FMS47/fTJ2aQbx6VS+u6Bup9gVSaRT0IhVo2/5s7p72K2tTDnJxj+Y8PaI7EfXVvkAql4JepIIsStjLfdNXEVTDMPH6vgzv3sLtkqSaUtCL+FhJieXNRZt547vNdGvZgInX96NVmObixT0KehEfyswp5IHPVrEoYR+j+kbx3OXd9e5WcZ2CXsRHNuw+yB0fx7HrQC7PXtad6wdGa8FV/IKCXsQHvlyVwsMz19Cgdk2mjxtEv9Zhbpck8l8KepHTUFhcwgvzEpi8ZCsD2oTx1nV9aFq/tttliRxFQS9yivYdyuPuT1eyfGs6Nw1pw2MXd1GfGvFLCnqRUxC3PYO7PokjM7eQ8aN7M7J3pNsliRyXgl7kJFhr+XjZDp6Zu44WDevwxV0D6NKigdtlifwmBb1IOeUVFvP47LXMiEvmnE4RvHFNHxrW1e39xAdKiiE3A4ryoGGUz59eQS9SDjvTc7jzkzjWphzkvmEx3DcsRh0n5bcV5kJ2KmSlOp+zUyF7H2Tvh6x93sf7nW05aWBLIGoA3Pqtz0tR0IucwL83p3LPtJUUl1jeH+thWJdmbpckbrDWOes+HNpZ3tA+XoAXHCr7eULqQWg4hDaFxm0gygP1mkJoBDRuWyGlK+hFjsNayzs/buEfCzYS07Q+797QjzbhoW6XJRWlMA8ytkF6EqRvcT5nbD8S4tmpUFJUxoEG6jbxhnU4RPZzQjs0/EiAh3r3hUZASOW3w1DQi5ThUF4hD32+mgXr9nJpr5a8NKoHdUP0z6XK+2+Ye4M8zfs5PQkykwF7ZGydxtCoNTSIhBa9vGEd4XzUizgS4HXDoIZ/t7nQT67IMRL3HWLcR3FsT8vhb5d05eYhbdTKoCopzIOMrccE+RZI31p2mIe1h+gzoEl7CGvnPA5r6wR4gFDQi5TyTfxuHvp8NXVCgvjk1oEMatfE7ZKkLIW5zpn5UUGeBGlJcDCFo8M8zAnw1oNLBXm7gAvz36KgFwGKikv4x8JNTPxxC32iG/H2dX1p0bCO22VVb9Y6i5upCbB/E6RuhP0bvWGefPTYOmHOGXmbIUeCvEk753Odxu7U70cU9FLtpWcXcM+0X1mSmMZ1A6N54tKu1Ar27znXgFJSApk7IHWTE+SpCUe+zss8Mi6kPkR0hDZneoPcO8WiMD8hBb1Ua2uSD3Dnx7+SmpXPy1f25GpPK7dLClzFhc70yuEz81Tvx/7NUJR7ZFzdcIjoDN1HQXgniPB+1G8BWis5JQp6qbY+W7GTx79cS0S9Wsy8YzA9ohq6XVJgKMiBtM3OWXlqgjfUNznz6KUvT2zYCsK9Z+jhHZ1wj+hUbebNK5OCXqqd/KJinp67nk+X7eDMDuG8eW0fwkJD3C6ratq/GXYs9Z6Ze+fRD+zgv4uhpoYztRLeCTpf7IR5eEfno1Y9V0uvThT0Uq2kZeUz7qM44rZncOfQ9jx0QSeC1Mrg5GSmwNqZEP857FnjbAuqBeExzpuFeo9xzszDOznz6MG13K1XFPRSfWxJzeKmKSvYezCPCWP68vueLdwuqerISYcNcyB+Bmz7GbDQsi9c+AJ0vNB5K7+fv2moOlPQS7WwdEsad3wcR80gw/Rxg+gTras0TqggBzbNd8J980IoKYQmHWDoI9DjKudsXaoEBb0EvJlxyTwyaw1tmoQy+cb+tAqr/F4jVUZxEWxd7IT7hrlQkAX1msPA26HHldCit658qYLKFfTGmOHAeCAIeM9a+2IZY64GnsJZhVltrR3j3V4MxHuH7bDWjvBB3SInZK3l9e828+b3mxnSoQlvX9ePhnXUP/5/WAvJsRD/Gaz7wmneVashdLvcOXNvc6amZaq4Ewa9MSYImACcDyQDK4wxc6y160uNiQEeBYZYazOMMU1LPUWutba3j+sW+U35RcX8ZcYavly1i2s8rfj75d11P9dj7UtwFlTjP4cD250F1U7DnXCPuUCLqAGkPGf0A4BEa20SgDFmOjASWF9qzG3ABGttBoC1dp+vCxUpr/TsAm7/KJYV2zL4y/BO3Hl2ezUlOywzudQVM/HO5Y9tz4azH4Yul0BtvZcgEJUn6COBnaUeJwMDjxnTEcAYswRneucpa+18777axphYoAh40Vo7+9hvYIwZB4wDiI6OPqkXIFLa1v3Z3DRlObsy83hrTB8u6dnS7ZLcl5MO67905t23LwGscxnk8Jec6Zn6upFKoPPVYmwwEAMMBaKAn4wxPay1B4DW1toUY0w7YJExJt5au6X0wdbaScAkAI/HYxE5Bcu3pjPuo1hqGMO02wbRr3U1vrKmIAc2fQNrPofE77xXzMTAOY85rQV0xUy1Up6gTwFKNwCJ8m4rLRlYZq0tBLYaYzbhBP8Ka20KgLU2yRizGOgDbEHEh2avTOEvM9YQFVaHKTf2p3WTanQnKGudBdTDPWR2LIOEr6Ew2+kPM/B2Z969RS9dMVNNlSfoVwAxxpi2OAE/GhhzzJjZwLXAFGNMOM5UTpIxpjGQY63N924fArzss+ql2rPW8ub3ibz+3SYGtQvj3es9NKwboFfWlJQ47XnL6vKYm3FkXO1G0GOUE+6th+iKGTlx0Ftri4wxdwMLcObfJ1tr1xljngFirbVzvPsuMMasB4qBP1tr04wxg4F3jTElQA2cOfr1x/lWIiclv6iYR2fGM2tlCqP6RvHCFT0ICQ6AK2uKi5w7JJXV5bEw+8i4OmFO75iuI4/0kIno5Nz6TmfuUoqx1r+mxD0ej42NjXW7DPFzB3IKuP2jOJZtTedP53fk7nM7VL0rawrzvF0eDzcESzjS5bG44Mi4BpGlujt2PNK6NzTcvdrF7xhj4qy1nrL26Z2xUuVsT8vmpikrSM7IZfzo3ozsHel2Sb8tP8t7Vl6qZW9qgnPtui1xxpgaTr+YiM5O75jDTcHCY6B2A1fLl6pPQS9VSuy2dMZ9FIe1lk9uG0j/Nn7cu9xaiPsAFjwGhTnOtqAQ5+qXlr2h5zVHbqoR1h5q1na1XAlcCnqpMuas3sVDn68mslEdJt/Yn7bhfnxlTU46zLkHEr6CdufAgHFOoDdqDUH6ZyeVSz9x4vestUz4IZF/LNzEgDZhvHtDPxr7841Ckn6EL26H7P1wwXMw6C6oEQCLxFJlKejFrxUUlfDYF/HMiEvmst4teenKnv574+6iAvjhOVgy3plbH/Mv59p1EZcp6MVvZeYUcsfHcSxNSuO+YTHcf16M/15Zsz8RZt4Cu1dBv5vgwuchRO2QxT8o6MUv7UjL4aYPlrMjPYfXru7FFX2j3C6pbNbCyo/hm4chOASu+Ri6XOp2VSJHUdCL3/l1Rwa3TY2lqMTy0S0DGdSuidsllS03A+be5zQMa/M7uGISNFATNfE/CnrxK1+v2c2Dn62iecPaTL6xP+0j6rldUtm2LYFZ4yBrD5z3FAy+V60GxG8p6MUvWGuZ+GMSL81PwNO6MZP+4CHMH6+sKS6ExS/Cv1+FsLZwy0Kn5a+IH1PQi+sKi0v42+y1TF+xk0t7teSVK3tSu6Yfnh2nJ8HM2yAlFvpc7/Rzr+Wn/+MQKUVBL67KyC7grk9+ZWlSGvec24EHzutIjRp+dmWNtbB6Osx7yJmeueoD54YdIlWEgl5ck7jvELdMjWX3gTxevaoXo/r54ZU1eZnw1YOwdobT8vfyd6FRqxMfJ+JHFPTiih827uPeT1dSq2YQ08b56d2gdvzHmao5mALnPg5nPqgFV6mSFPRSqay1vP/zVp6ft4HOzRvwz7EeIhvVcbusoxUXwU+vwE8vQ6NouHkBtOrvdlUip0xBL5Umv6iYx79Yy+dxyVzUvTmvXt2LuiF+9iOYsR1m3QY7l0HP0XDxK2oTLFWen/0rk0C1PyufOz6KI3Z7BvcOi+H+YTH+t+i65nP4+kHn61HvQ48r3a1HxEcU9FLhNuw+yK1TY9mflc//XduHS3v52btH8w7CvD/DmunQaiBc8U9o3NrtqkR8RkEvFWrBuj088K9V1K8dzOd3nEHPqEZul3S05FinGdmBHTD0UfjdQ+oXLwFHP9FSIay1vL14C68s2EivqIZM+oOHZg386A5KJcXw82vwwwvOPVlv+gaiB7ldlUiFUNCLz+UVFvOXGWuYs3oXI3u35KVRfvRO1+IiSN3gdJvcvgS6j4LfvwZ1/Ox/GiI+pKAXn9p7MI9xH8ayOjmTP1/YibuGtnevh3z+Idi7DvbEH/nYtx6K8iCkHlw2EXqNBn/tcS/iIwp68Zk1yQe47cNYDuUV8e4N/biwW/PK+cbWwsFdpQJ9Dexd6/SmOaxOY2jeA/rfCs26Q7uz1VJYqg0FvfjEXO+Nu8Pr1WLGHYPp2rKCrj0vLoTUjU6QHw71PfFOb/jDwto5Yd5rjBPuzbs78/A6c5dqSkEvp6WkxPLGd5t4c1EintaNmXhDP8Lr1fLNk+ceKBXo3o/UBCgucPYH14amXaHLCG+g94Bm3aBWfd98f5EAoaCXU5ZTUMSD/1rN/HV7uKpfFH+/vPup3bjbWufyxtKBviceMnccGRMa4QR5+zuheU/njL1JB10KKVIO+lcipyTlQC63TY0lYc9BHv99F245s+3JL7rmZUL85xD3gRPsABgIj3F6y3huckK9eQ+o38zXL0Gk2lDQy0mL257B7R/FkV9YzPtj+3NO56blP9haSPkV4qbA2plQmAPNesDwFyFqADTtAiF1K654kWpIQS8nZUZcMo/NiqdFo9pMu20gMc3KOR+elwlrPoO4qbA3HmqGOr1k+t0ILftqoVSkAinopVyKSywvz0/g3Z+SOKNdE96+ri+NT3RPV2udFgNxH8C6Wc7Ze/MezhuUelylrpAilURBLyd0KK+Q+6avYlHCPq4bGM1TI7pRM6jG8Q/IPXBk7n3vWu/Z+1Xes/c+OnsXqWQKevlNO9JyuGXqCpL2Z/PsyG7ccEabsgdaC8krnHBfOwuKcqFFL7jkDWeKRpc8irhGQS/HtXRLGnd9EkeJhQ9vHsCQDuH/Oyg3wzv3/oHTXiCkHvS65sjZu4i4TkEv/8Nay6fLd/Dkl+uIblKX98f2p214aOkBsHP5kbn3ojwn1C8d7zQJ09m7iF9R0MtR0rML+OsX8Xyzdg9ndYzg/67tQ8M6NZ2duRmw+l9OwKdugJD60HsM9B0LLXu7WreIHF+5gt4YMxwYDwQB71lrXyxjzNXAU4AFVltrx3i3jwUe9w77u7V2qg/qlgrw/Ya9PDwznszcAh4e3plxZ7UjyADblzrhvn629+y9L4z4P+h2BdSq53bZInICJwx6Y0wQMAE4H0gGVhhj5lhr15caEwM8Cgyx1mYYY5p6t4cBTwIenF8Acd5jM479PuKerPwi/v7Veqav2Enn5vX58OYBdG1UBMsnes/eE7xn79dBv7HOIquIVBnlOaMfACRaa5MAjDHTgZHA+lJjbgMmHA5wa+0+7/YLgW+tteneY78FhgPTfFO+nK5lSWn86fPV7DqQy51D23P/WS2ptfxtWDLeue490gMj3oLuV0BI6ImfUET8TnmCPhLYWepxMjDwmDEdAYwxS3Cmd56y1s4/zrGRx34DY8w4YBxAdHR0eWuX05BXWMyrCzfy3s9badW4Lp+NG4jnwAJ45zI4tBu6XgZnPeS8wUlEqjRfLcYGAzHAUCAK+MkYU+6EsNZOAiYBeDwe66Oa5DjWpmTy4Ger2LQ3i+sGRvN4t/3UWXC509s90gNXTYXoY3+Xi0hVVZ6gTwFalXoc5d1WWjKwzFpbCGw1xmzCCf4UnPAvfeziUy1WTk9RcQnvLN7C+O83ExYawvRRTRiU+Dx8Og8atoJR7zuXR+qdqyIBpTxBvwKIMca0xQnu0cCYY8bMBq4FphhjwnGmcpKALcDzxpjG3nEX4CzaSiVLSs3iwc9Ws2rnAa7pVpdnGn1NrW+mQHAdGPYkDLoTatZxu0wRqQAnDHprbZEx5m5gAc78+2Rr7TpjzDNArLV2jnffBcaY9UAx8GdrbRqAMeZZnF8WAM8cXpiVylFSYvl42Xaen7eB0KASvuq/mu6bJ0LSIefdq0Mfg3oRbpcpIhXIWOtfU+Iej8fGxsa6XUZA2J2Zy19mrOHfm1N5MGojdxV+SHDmNuhwHpz/LDTr6naJIuIjxpg4a62nrH16Z2wAstby5apd/O3LtXQqTmRZixk02/8rRHSB62ZCzHlulygilUhBH2DSswt4fHY8K+PX8VajLzg7bxEURDhdJPvcoHusilRD+lcfQL7fsJenZyznmoKZvFl3HkGFwJkPwpkP6CYfItWYgj4AZOUX8dzceEpWfsLskM8JCzoA3a6CYU9AI70BTaS6U9BXccuS0pg2/UNuz5tMl5o7KIkcAMNfgKgy12REpBpS0FdReYXFTJ2zgA6rXuaNoJXkN2gFF02lRteResOTiBxFQV8FbUhMYvNnf+WW/PkU1qxL/tCnqTX4Tgiu5XZpIuKHFPRVSFF+Dsumv0DPpH8SY/LZ0/E6oi57GkKbuF2aiPgxBX0VsXv5LMz8RxlSsof4emfQevQ/iGrV3e2yRKQKUND7ubTMQ2z65E+cse9fbCKapCHvM/j8K90uS0SqEAW9n8orLOZf3y2l93/u5wyzmV/Cr6TD9a/TsZGuhxeRk6Og9zPFJZZZvybzy/zp/K3wDerUKGH3+RMZPPhat0sTkSpKQe9HftqUykvz1jF8/xReD55Ndlhn6lz3CXXCO7hdmohUYQp6P7B+10Fe+GYDCRa8C4QAAAn6SURBVJsTebfu2/QNXovtcwOhF7+iHvEictoU9C7adSCXVxduYtbKZIbV3sSPDd6iTkk2jHgH0/vYe7uIiJwaBb0LDuYV8s7iLUz+eStQwpT2P3F2yiRM/fZw9Vz1iRcRn1LQV6KCohI+XbadNxclkp5dwJgeofyt8E3qbPveuVfrpeOhVn23yxSRAKOgrwTWWr5Zu4eX5yewLS2Hwe2b8Kwnj/aL74asvfD7V8Fzi3rUiEiFUNBXsNht6Tw/bwO/7jhAp2b1mXKjh6EZMzFzn4AGLeDmBRDZ1+0yRSSAKegrSFJqFi/NT2DBur00rV+Ll0b14MpuDQiaew9smAOdLobL3oY6jd0uVUQCnILex/Zn5fPm95v5dNkOagXX4E/nd+SW37Wlbtp6eG8kZGx3bsw9+B5N1YhIpVDQ+0huQTHv/5zExB+TyC0s5toBrbhvWEci6oXArx/CvD9D3SZw0zyIHuR2uSJSjSjoT1NxiWXmr8m8tnATew7mcUHXZjx8UWfaR9SDgmz44l5YMx3anQOj3oPQcLdLFpFqRkF/iqy1/LgplRe/SSBhzyF6t2rEm9f2YUDbMGdA6kb4bCykJsDQR+GsP0ONIHeLFpFqSUF/CrakZvHsV+tZvDGV6LC6TBjTl4t7NMccnnNf8znMvc9pX3DDLGh/rrsFi0i1pqA/CYfyCnlrUSKTl2yldnAQj/++C384ow0hwTWcAYV5sOBRiJ0M0WfAlZOhQUt3ixaRak9BXw4lJZbZq1J44ZsEUg/lc7Unij9f2JmI+qXu0Zq+FT4fC7tXw5D74Ny/QVBN94oWEfFS0J9AfHImT85Zy687DtCrVSP++QcPvVs1OnrQhq9g9l1ggNHToPPFrtQqIlIWBf1xpGXl84+FG5m+YidNQkN45cqejOobRY0apa59Ly6E756CpW9Byz5w1QfQuI1LFYuIlE1Bf4yi4hI++s92Xvt2E7kFxdwypC33nhdDg9qlpmGyUiF5BSwZDzv/A/1vgwufg+Bax39iERGXKOhL+SVxP0/NXcemvVn8LiacJy/tSocmtWFPPCTHQvJyJ+AztjkHhNR3Fly7j3K1bhGR36KgB5Izcnh+3gbmxe+hV6NcZp+TTS+WYr56EnathKI8Z2C95tCqv9NpMqo/tOgFIXXdLV5E5ASqddDn5Wbz5TfzSVr1A5eymZcabqV+3l5YCgSFQIve3lD3QKsB0CBS/WlEpMqpPkFvLWTuhJ3LsckryNy8lLrp67iGIqgBRfWjCI4e4gR6VH9o3kNz7iISEAI36AuyYdcqZ0798EfWXmeXqcXG4rZsrz2SnmcMo7NnGMH1m7tcsIhIxShX0BtjhgPjgSDgPWvti8fsvxF4BUjxbnrLWvued18xEO/dvsNaO8IHdf+v/CxI+OpIqO9ZC7bY2RfWjoLWZ/HdwdZMTAojuWYb7hvejesGRhMcVKNCyhER8RcnDHpjTBAwATgfSAZWGGPmWGvXHzP0X9bau8t4ilxrbe/TL/UEivLhi9shpB5E9oMzH4Co/pREepixIZeXFySQll3A6P7RTLmgI03qaVpGRKqH8pzRDwASrbVJAMaY6cBI4Nigd1doE/jjcmjS4b9dIlfuyOCpD9axOjmTfq0b88FNA+ge2dDlQkVEKld5gj4S2FnqcTIwsIxxo4wxZwGbgAestYePqW2MiQWKgBettbOPPdAYMw4YBxAdHX0S5R8johMA+w7l8fL8jcyIS6Zp/Vq8fk0vLusdeaS7pIhINeKrxdi5wDRrbb4x5nZgKnC4N29ra22KMaYdsMgYE2+t3VL6YGvtJGASgMfjsadaREFRCVN/2cb47zeTX1TMHWe35+5zO1CvVuCuOYuInEh5EjAFaFXqcRRHFl0BsNamlXr4HvByqX0p3s9JxpjFQB/gqKD3hZ3pOdw4ZTlbUrMZ2imCJy7pSruIer7+NiIiVU55gn4FEGOMaYsT8KOBMaUHGGNaWGt3ex+OADZ4tzcGcrxn+uHAEEr9EvClZg1q06ZJKI9d3IVhXZpVxLcQEamSThj01toiY8zdwAKcyysnW2vXGWOeAWKttXOAe40xI3Dm4dOBG72HdwHeNcaUADVw5ugrZBE3JLgG79/YvyKeWkSkSjPWnvKUeIXweDw2NjbW7TJERKoUY0yctdZT1j69W0hEJMAp6EVEApyCXkQkwCnoRUQCnIJeRCTAKehFRAKcgl5EJMD53XX0xphUYPtpPEU4sN9H5fgbvbaqK5Bfn16bf2htrY0oa4ffBf3pMsbEHu9NA1WdXlvVFcivT6/N/2nqRkQkwCnoRUQCXCAG/SS3C6hAem1VVyC/Pr02Pxdwc/QiInK0QDyjFxGRUhT0IiIBLmCC3hgz3Biz0RiTaIx5xO16fMkY08oY84MxZr0xZp0x5j63a/I1Y0yQMWalMeYrt2vxJWNMI2PMDGNMgjFmgzHmDLdr8iVjzAPen8m1xphpxpjabtd0qowxk40x+4wxa0ttCzPGfGuM2ez93NjNGk9VQAS9MSYImABcBHQFrjXGdHW3Kp8qAv5kre0KDAL+GGCvD+A+vLegDDDjgfnW2s5ALwLoNRpjIoF7AY+1tjvOHehGu1vVafkAGH7MtkeA7621McD33sdVTkAEPTAASLTWJllrC4DpwEiXa/IZa+1ua+2v3q8P4YRFpLtV+Y4xJgr4Pc6N5QOGMaYhcBbwPoC1tsBae8DdqnwuGKhjjAkG6gK7XK7nlFlrf8K5FWppI4Gp3q+nApdValE+EihBHwnsLPU4mQAKwtKMMW2APsAydyvxqTeAvwAlbhfiY22BVGCKd1rqPWNMqNtF+Yq1NgX4B7AD2A1kWmsXuluVzzWz1u72fr0HaOZmMacqUIK+WjDG1ANmAvdbaw+6XY8vGGMuAfZZa+PcrqUCBAN9gXestX2AbKrof/3L4p2vHonzC60lEGqMud7dqiqOda5Fr5LXowdK0KcArUo9jvJuCxjGmJo4If+JtXaW2/X40BBghDFmG86U27nGmI/dLclnkoFka+3h/33NwAn+QHEesNVam2qtLQRmAYNdrsnX9hpjWgB4P+9zuZ5TEihBvwKIMca0NcaE4CwIzXG5Jp8xxhiced4N1trX3K7Hl6y1j1pro6y1bXD+3hZZawPirNBauwfYaYzp5N00DFjvYkm+tgMYZIyp6/0ZHUYALTZ7zQHGer8eC3zpYi2nLNjtAnzBWltkjLkbWICz8j/ZWrvO5bJ8aQhwAxBvjFnl3faYtXaeizVJ+dwDfOI9AUkCbnK5Hp+x1i4zxswAfsW5MmwlVbhlgDFmGjAUCDfGJANPAi8CnxljbsFpn361exWeOrVAEBEJcIEydSMiIsehoBcRCXAKehGRAKegFxEJcAp6EZEAp6AXEQlwCnoRkQD3/7YYbUAfOm6zAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Qn 3**\n",
        "d. How does the dropout work, and what is the purpose of dropouts?"
      ],
      "metadata": {
        "id": "de7X5Had3GjK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dropout is a regularization technique for neural network models where randomly selected neurons are ignored during the training, thus they are 'dropped out' randomly.\n",
        "\n",
        "Thus, making their contribution to the activation of downstream neurons is temporarily removed on the forward pass, and any weight updates aren't applied on the backward pass.\n",
        "\n",
        "Then, as the neural network learns, neuron weights settle into their context within the network. Weights od neurons are tuned for specific features, providing some specialisation.\n",
        "\n",
        "After which, the neighbouring neurons come to rely on this specialisaton, which if taken too far, can result in a fragile model too specialise for the training data.\n",
        "\n",
        "The effect is that the network becomes less sensitive to the specific weights of the neurons. This would then result ina network capable of better generalisation and less likely to overfit the training data."
      ],
      "metadata": {
        "id": "ySE4a9xBfP1l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Qn 3**\n",
        "e. Besides early stopping and dropout, what is another approach that you could take to address overfitting in the model, and how does it work?\n",
        "\n",
        "Implement the approach.\n",
        "\n",
        "Ans: we can either use Regularisation or Normalisation.\n",
        "\n",
        "Here we implement Normalisation."
      ],
      "metadata": {
        "id": "5I3oS5wh3G8D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(hidden_layer):\n",
        "  ffn = models.Sequential()\n",
        "  ffn.add(layers.Dense(units=hidden_layer, activation='relu', input_shape=(77,)))\n",
        "  ffn.add(layers.BatchNormalization())\n",
        "  ffn.add(layers.Dense(units=hidden_layer, activation='relu'))\n",
        "  ffn.add(layers.Dense(units=hidden_layer, activation='relu'))\n",
        "  ffn.add(layers.Dense(units=1, activation='sigmoid'))\n",
        "  opt=optimizers.Adam()\n",
        "  ffn.compile(\n",
        "      optimizer=opt,\n",
        "      loss='BinaryCrossentropy',\n",
        "      metrics=['accuracy']\n",
        "  )\n",
        "\n",
        "  return ffn"
      ],
      "metadata": {
        "id": "owd6B2P31seL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Qn 4**\n",
        "a. Record yourself with a wav file for 5 seconds, either in a positive or negative manner. Preprocess the data using the preprocess script and prepare the data set."
      ],
      "metadata": {
        "id": "634ZCVJ64WWl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import soundfile as sf\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "\n",
        "from collections import OrderedDict\n",
        "\n",
        "import json"
      ],
      "metadata": {
        "id": "sfvkdLgC-EBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(filepath):\n",
        "\n",
        "    '''\n",
        "    Source: https://github.com/danz1ka19/Music-Emotion-Recognition/blob/master/Feature-Extraction.py\n",
        "    Modified to process a single file\n",
        "\n",
        "        function: extract_features\n",
        "        input: path to mp3 files\n",
        "        output: csv file containing features extracted\n",
        "\n",
        "        This function reads the content in a directory and for each audio file detected\n",
        "        reads the file and extracts relevant features using librosa library for audio\n",
        "        signal processing\n",
        "    '''\n",
        "\n",
        "    feature_set = {}  # Features\n",
        "\n",
        "    # Reading audio file\n",
        "    y, sr = librosa.load(filepath)\n",
        "    S = np.abs(librosa.stft(y, n_fft=512))\n",
        "    # https://librosa.org/doc/main/generated/librosa.stft.html (set 512 for speech processing)\n",
        "\n",
        "    # Extracting Features\n",
        "    tempo, beats = librosa.beat.beat_track(y=y, sr=sr)\n",
        "    chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr, n_fft=512)\n",
        "\n",
        "    chroma_cq = librosa.feature.chroma_cqt(y=y, sr=sr)\n",
        "\n",
        "    chroma_cens = librosa.feature.chroma_cens(y=y, sr=sr)\n",
        "    melspectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=512)\n",
        "    rmse = librosa.feature.rms(y=y)[0]\n",
        "    cent = librosa.feature.spectral_centroid(y=y, sr=sr, n_fft=512)\n",
        "    spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr, n_fft=512)\n",
        "    contrast = librosa.feature.spectral_contrast(S=S, sr=sr, n_fft=512)\n",
        "    rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr, n_fft=512)\n",
        "    poly_features = librosa.feature.poly_features(S=S, sr=sr, n_fft=512)\n",
        "\n",
        "    tonnetz = librosa.feature.tonnetz(y=y, sr=sr)\n",
        "\n",
        "    zcr = librosa.feature.zero_crossing_rate(y)\n",
        "    harmonic = librosa.effects.harmonic(y)\n",
        "    percussive = librosa.effects.percussive(y)\n",
        "\n",
        "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_fft=512)\n",
        "    mfcc_delta = librosa.feature.delta(mfcc)\n",
        "\n",
        "    onset_frames = librosa.onset.onset_detect(y=y, sr=sr)\n",
        "    frames_to_time = librosa.frames_to_time(onset_frames[:20], sr=sr)\n",
        "\n",
        "    # Concatenating Features into one csv and json format\n",
        "    feature_set['filename'] = filepath  # song name\n",
        "    feature_set['tempo'] = tempo  # tempo\n",
        "    feature_set['total_beats'] = sum(beats)  # beats\n",
        "    feature_set['average_beats'] = np.average(beats)\n",
        "    feature_set['chroma_stft_mean'] = np.mean(chroma_stft)  # chroma stft\n",
        "    feature_set['chroma_stft_var'] = np.var(chroma_stft)\n",
        "\n",
        "    feature_set['chroma_cq_mean'] = np.mean(chroma_cq)  # chroma cq\n",
        "    feature_set['chroma_cq_var'] = np.var(chroma_cq)\n",
        "\n",
        "    feature_set['chroma_cens_mean'] = np.mean(chroma_cens)  # chroma cens\n",
        "    feature_set['chroma_cens_var'] = np.var(chroma_cens)\n",
        "    feature_set['melspectrogram_mean'] = np.mean(melspectrogram)  # melspectrogram\n",
        "    feature_set['melspectrogram_var'] = np.var(melspectrogram)\n",
        "    feature_set['mfcc_mean'] = np.mean(mfcc)  # mfcc\n",
        "    feature_set['mfcc_var'] = np.var(mfcc)\n",
        "    feature_set['mfcc_delta_mean'] = np.mean(mfcc_delta)  # mfcc delta\n",
        "    feature_set['mfcc_delta_var'] = np.var(mfcc_delta)\n",
        "    feature_set['rmse_mean'] = np.mean(rmse)  # rmse\n",
        "    feature_set['rmse_var'] = np.var(rmse)\n",
        "    feature_set['cent_mean'] = np.mean(cent)  # cent\n",
        "    feature_set['cent_var'] = np.var(cent)\n",
        "    feature_set['spec_bw_mean'] = np.mean(spec_bw)  # spectral bandwidth\n",
        "    feature_set['spec_bw_var'] = np.var(spec_bw)\n",
        "    feature_set['contrast_mean'] = np.mean(contrast)  # contrast\n",
        "    feature_set['contrast_var'] = np.var(contrast)\n",
        "    feature_set['rolloff_mean'] = np.mean(rolloff)  # rolloff\n",
        "    feature_set['rolloff_var'] = np.mean(rolloff)\n",
        "    feature_set['poly_mean'] = np.mean(poly_features)  # poly features\n",
        "    feature_set['poly_var'] = np.mean(poly_features)\n",
        "\n",
        "    feature_set['tonnetz_mean'] = np.mean(tonnetz)  # tonnetz\n",
        "    feature_set['tonnetz_var'] = np.var(tonnetz)\n",
        "\n",
        "    feature_set['zcr_mean'] = np.mean(zcr)  # zero crossing rate\n",
        "    feature_set['zcr_var'] = np.var(zcr)\n",
        "    feature_set['harm_mean'] = np.mean(harmonic)  # harmonic\n",
        "    feature_set['harm_var'] = np.var(harmonic)\n",
        "    feature_set['perc_mean'] = np.mean(percussive)  # percussive\n",
        "    feature_set['perc_var'] = np.var(percussive)\n",
        "    feature_set['frame_mean'] = np.mean(frames_to_time)  # frames\n",
        "    feature_set['frame_var'] = np.var(frames_to_time)\n",
        "\n",
        "    for ix, coeff in enumerate(mfcc):\n",
        "        feature_set['mfcc' + str(ix) + '_mean'] = coeff.mean()\n",
        "        feature_set['mfcc' + str(ix) + '_var'] = coeff.var()\n",
        "\n",
        "    return feature_set"
      ],
      "metadata": {
        "id": "zXuTtqav__lQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_features_dict = extract_features('/content/drive/MyDrive/Introduction.wav')\n",
        "df1 = pd.DataFrame([new_features_dict])\n",
        "df1.to_csv('./new_record.csv', index=False)"
      ],
      "metadata": {
        "id": "zfpTU_m4ALzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Qn 4**\n",
        "b. Do a model prediction on your sample test dataset and obtain the predicted label using a threshold of 0.5. The model used is the optimised pretrained model using the selected optimal batch size and optimal number of neurons."
      ],
      "metadata": {
        "id": "76W0WTR24zRf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model=models.load_model('/content/fnn_model.hdf5')"
      ],
      "metadata": {
        "id": "BYfaGAXxtCOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.drop(labels='filename', axis = 1, inplace=True)"
      ],
      "metadata": {
        "id": "ViHiXZwf3j0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "1PJtIT3VwRfF",
        "outputId": "02dacca3-1e2e-46e1-9999-da6af1a8220d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        tempo  total_beats  average_beats  chroma_stft_mean  chroma_stft_var  \\\n",
              "0  161.499023         1230     111.818182          0.695642         0.050151   \n",
              "\n",
              "   chroma_cq_mean  chroma_cq_var  chroma_cens_mean  chroma_cens_var  \\\n",
              "0        0.402822       0.069577          0.247033         0.022308   \n",
              "\n",
              "   melspectrogram_mean  ...  mfcc15_mean  mfcc15_var  mfcc16_mean  mfcc16_var  \\\n",
              "0             0.221182  ...     3.117354   66.570526    -6.447403    62.48204   \n",
              "\n",
              "   mfcc17_mean  mfcc17_var  mfcc18_mean  mfcc18_var  mfcc19_mean  mfcc19_var  \n",
              "0     1.576906   62.275311    -4.977098   46.403564     1.143298   57.712887  \n",
              "\n",
              "[1 rows x 77 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e5a3dbb7-a2d6-4d6f-b310-108c22d7f3af\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tempo</th>\n",
              "      <th>total_beats</th>\n",
              "      <th>average_beats</th>\n",
              "      <th>chroma_stft_mean</th>\n",
              "      <th>chroma_stft_var</th>\n",
              "      <th>chroma_cq_mean</th>\n",
              "      <th>chroma_cq_var</th>\n",
              "      <th>chroma_cens_mean</th>\n",
              "      <th>chroma_cens_var</th>\n",
              "      <th>melspectrogram_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>mfcc15_mean</th>\n",
              "      <th>mfcc15_var</th>\n",
              "      <th>mfcc16_mean</th>\n",
              "      <th>mfcc16_var</th>\n",
              "      <th>mfcc17_mean</th>\n",
              "      <th>mfcc17_var</th>\n",
              "      <th>mfcc18_mean</th>\n",
              "      <th>mfcc18_var</th>\n",
              "      <th>mfcc19_mean</th>\n",
              "      <th>mfcc19_var</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>161.499023</td>\n",
              "      <td>1230</td>\n",
              "      <td>111.818182</td>\n",
              "      <td>0.695642</td>\n",
              "      <td>0.050151</td>\n",
              "      <td>0.402822</td>\n",
              "      <td>0.069577</td>\n",
              "      <td>0.247033</td>\n",
              "      <td>0.022308</td>\n",
              "      <td>0.221182</td>\n",
              "      <td>...</td>\n",
              "      <td>3.117354</td>\n",
              "      <td>66.570526</td>\n",
              "      <td>-6.447403</td>\n",
              "      <td>62.48204</td>\n",
              "      <td>1.576906</td>\n",
              "      <td>62.275311</td>\n",
              "      <td>-4.977098</td>\n",
              "      <td>46.403564</td>\n",
              "      <td>1.143298</td>\n",
              "      <td>57.712887</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 77 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e5a3dbb7-a2d6-4d6f-b310-108c22d7f3af')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e5a3dbb7-a2d6-4d6f-b310-108c22d7f3af button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e5a3dbb7-a2d6-4d6f-b310-108c22d7f3af');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = best_model.predict(df1)"
      ],
      "metadata": {
        "id": "7VcIQyWjriqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17shtrpuroWO",
        "outputId": "d0d18bc6-e3e2-4285-8c44-ac405b006831"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Qn 4**\n",
        "c. Find the most important features on the model prediction for your test sample using SHAP. Plot the local feature importance with a force plot and explain your\n",
        "observations"
      ],
      "metadata": {
        "id": "nd1IAsfU5Qs-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap"
      ],
      "metadata": {
        "id": "soRi3eiqstbG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shap"
      ],
      "metadata": {
        "id": "g1jYc-QVs10u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras.backend\n",
        "shap.explainers._deep.deep_tf.op_handlers['AddV2'] = shap.explainers._deep.deep_tf.passthrough\n",
        "\n",
        "shap_exp = shap.DeepExplainer(best_model, X_train_scaled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6U71WCoDsXCj",
        "outputId": "f44a861e-fdc5-482b-d12a-269e69297b57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n",
            "You have provided over 5k background samples! For better performance consider using smaller random sample.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shap_values = shap_exp.shap_values(X_test_scaled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_4kUmJZuekp",
        "outputId": "2e833447-6bd1-4c54-9311-147ea83af57e"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shap.summary_plot(shap_values[0], plot_type='bar', feature_names=df1.columns)"
      ],
      "metadata": {
        "id": "0LeN8KEcmTBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap.decision_plot(shap_exp.expected_value[0].numpy(), shap_values[0][0], features = df1.iloc[0,:], feature_names = X_test.columns.tolist())"
      ],
      "metadata": {
        "id": "ol0fnmYAo-pT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap.plots._waterfall.waterfall_legacy(shap_exp.expected_value[0].numpy(), shap_values[0][0], feature_names = X_test.columns)"
      ],
      "metadata": {
        "id": "WPP1SC3pqH0V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}